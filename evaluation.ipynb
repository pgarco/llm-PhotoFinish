{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/52/11/9eac327a38834f162b8250aab32a6781339c69afe7574368fffe46387edf/pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.23.2 (from pandas)\n",
      "  Obtaining dependency information for numpy>=1.23.2 from https://files.pythonhosted.org/packages/58/b0/034eb5d5ba12d66ab658ff3455a31f20add0b78df8203c6a7451bd1bee21/numpy-2.2.1-cp311-cp311-macosx_14_0_arm64.whl.metadata\n",
      "  Downloading numpy-2.2.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/paulina/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/11/c3/005fcca25ce078d2cc29fd559379817424e94885510568bc1bc53d7d5846/pytz-2024.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/a6/ab/7e5f53c3b9d14972843a647d8d7a853969a58aecc7559cb3267302c94774/tzdata-2024.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/paulina/.pyenv/versions/3.11.5/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.1-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.1 pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_message</th>\n",
       "      <th>system_prompt_file</th>\n",
       "      <th>model_name</th>\n",
       "      <th>llm_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi!</td>\n",
       "      <td>system2.txt</td>\n",
       "      <td>OpenAI-GPT-4o-mini</td>\n",
       "      <td>¡Hola!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi!</td>\n",
       "      <td>system2.txt</td>\n",
       "      <td>Groq-LLama3-8B-8192</td>\n",
       "      <td>¡hola!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi!</td>\n",
       "      <td>system1.txt</td>\n",
       "      <td>OpenAI-GPT-4o-mini</td>\n",
       "      <td>¡Hola!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi!</td>\n",
       "      <td>system1.txt</td>\n",
       "      <td>Groq-LLama3-8B-8192</td>\n",
       "      <td>¿Qué onda, homes?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can you tell me a joke?</td>\n",
       "      <td>system2.txt</td>\n",
       "      <td>OpenAI-GPT-4o-mini</td>\n",
       "      <td>¿Me puedes contar un chiste?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can you tell me a joke?</td>\n",
       "      <td>system2.txt</td>\n",
       "      <td>Groq-LLama3-8B-8192</td>\n",
       "      <td>¡Claro! (Of course!) Here's one:\\n\\n¿Por qué e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Can you tell me a joke?</td>\n",
       "      <td>system1.txt</td>\n",
       "      <td>OpenAI-GPT-4o-mini</td>\n",
       "      <td>Claro, aquí te va un chiste:\\n\\n¿Por qué los p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Can you tell me a joke?</td>\n",
       "      <td>system1.txt</td>\n",
       "      <td>Groq-LLama3-8B-8192</td>\n",
       "      <td>¡eh, qué onda! Here's one, ¡primo!\\n\\n¿Sabes p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>system2.txt</td>\n",
       "      <td>OpenAI-GPT-4o-mini</td>\n",
       "      <td>¿Cuál es la capital de Francia?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>system2.txt</td>\n",
       "      <td>Groq-LLama3-8B-8192</td>\n",
       "      <td>La capital de Francia es París.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>system1.txt</td>\n",
       "      <td>OpenAI-GPT-4o-mini</td>\n",
       "      <td>¿Qué onda? La capital de Francia es París.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>system1.txt</td>\n",
       "      <td>Groq-LLama3-8B-8192</td>\n",
       "      <td>¡hombre! The capital of Francia, or France, is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Translate this sentence: \"Good morning!\"</td>\n",
       "      <td>system2.txt</td>\n",
       "      <td>OpenAI-GPT-4o-mini</td>\n",
       "      <td>¡Buenos días!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Translate this sentence: \"Good morning!\"</td>\n",
       "      <td>system2.txt</td>\n",
       "      <td>Groq-LLama3-8B-8192</td>\n",
       "      <td>¡Buenos días!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Translate this sentence: \"Good morning!\"</td>\n",
       "      <td>system1.txt</td>\n",
       "      <td>OpenAI-GPT-4o-mini</td>\n",
       "      <td>¡Buenos días!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Translate this sentence: \"Good morning!\"</td>\n",
       "      <td>system1.txt</td>\n",
       "      <td>Groq-LLama3-8B-8192</td>\n",
       "      <td>¡Eh, buena onda! ¡Buenos días!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explain quantum mechanics in simple terms.</td>\n",
       "      <td>system2.txt</td>\n",
       "      <td>OpenAI-GPT-4o-mini</td>\n",
       "      <td>Explica la mecánica cuántica en términos simples.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Explain quantum mechanics in simple terms.</td>\n",
       "      <td>system2.txt</td>\n",
       "      <td>Groq-LLama3-8B-8192</td>\n",
       "      <td>¡Claro! Aquí te explico la mecánica cuántica d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Explain quantum mechanics in simple terms.</td>\n",
       "      <td>system1.txt</td>\n",
       "      <td>OpenAI-GPT-4o-mini</td>\n",
       "      <td>Explicar la mecánica cuántica en términos senc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Explain quantum mechanics in simple terms.</td>\n",
       "      <td>system1.txt</td>\n",
       "      <td>Groq-LLama3-8B-8192</td>\n",
       "      <td>¡oye, homes! Let me break down quantum mechani...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  user_message system_prompt_file  \\\n",
       "0                                          hi!        system2.txt   \n",
       "1                                          hi!        system2.txt   \n",
       "2                                          hi!        system1.txt   \n",
       "3                                          hi!        system1.txt   \n",
       "4                      Can you tell me a joke?        system2.txt   \n",
       "5                      Can you tell me a joke?        system2.txt   \n",
       "6                      Can you tell me a joke?        system1.txt   \n",
       "7                      Can you tell me a joke?        system1.txt   \n",
       "8               What is the capital of France?        system2.txt   \n",
       "9               What is the capital of France?        system2.txt   \n",
       "10              What is the capital of France?        system1.txt   \n",
       "11              What is the capital of France?        system1.txt   \n",
       "12    Translate this sentence: \"Good morning!\"        system2.txt   \n",
       "13    Translate this sentence: \"Good morning!\"        system2.txt   \n",
       "14    Translate this sentence: \"Good morning!\"        system1.txt   \n",
       "15    Translate this sentence: \"Good morning!\"        system1.txt   \n",
       "16  Explain quantum mechanics in simple terms.        system2.txt   \n",
       "17  Explain quantum mechanics in simple terms.        system2.txt   \n",
       "18  Explain quantum mechanics in simple terms.        system1.txt   \n",
       "19  Explain quantum mechanics in simple terms.        system1.txt   \n",
       "\n",
       "             model_name                                       llm_response  \n",
       "0    OpenAI-GPT-4o-mini                                             ¡Hola!  \n",
       "1   Groq-LLama3-8B-8192                                             ¡hola!  \n",
       "2    OpenAI-GPT-4o-mini                                             ¡Hola!  \n",
       "3   Groq-LLama3-8B-8192                                  ¿Qué onda, homes?  \n",
       "4    OpenAI-GPT-4o-mini                       ¿Me puedes contar un chiste?  \n",
       "5   Groq-LLama3-8B-8192  ¡Claro! (Of course!) Here's one:\\n\\n¿Por qué e...  \n",
       "6    OpenAI-GPT-4o-mini  Claro, aquí te va un chiste:\\n\\n¿Por qué los p...  \n",
       "7   Groq-LLama3-8B-8192  ¡eh, qué onda! Here's one, ¡primo!\\n\\n¿Sabes p...  \n",
       "8    OpenAI-GPT-4o-mini                    ¿Cuál es la capital de Francia?  \n",
       "9   Groq-LLama3-8B-8192                    La capital de Francia es París.  \n",
       "10   OpenAI-GPT-4o-mini         ¿Qué onda? La capital de Francia es París.  \n",
       "11  Groq-LLama3-8B-8192  ¡hombre! The capital of Francia, or France, is...  \n",
       "12   OpenAI-GPT-4o-mini                                      ¡Buenos días!  \n",
       "13  Groq-LLama3-8B-8192                                      ¡Buenos días!  \n",
       "14   OpenAI-GPT-4o-mini                                      ¡Buenos días!  \n",
       "15  Groq-LLama3-8B-8192                     ¡Eh, buena onda! ¡Buenos días!  \n",
       "16   OpenAI-GPT-4o-mini  Explica la mecánica cuántica en términos simples.  \n",
       "17  Groq-LLama3-8B-8192  ¡Claro! Aquí te explico la mecánica cuántica d...  \n",
       "18   OpenAI-GPT-4o-mini  Explicar la mecánica cuántica en términos senc...  \n",
       "19  Groq-LLama3-8B-8192  ¡oye, homes! Let me break down quantum mechani...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./results/combined_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
